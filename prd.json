{
  "project": "Chess Speedrun Learning System",
  "branchName": "ralph/chess-speedrun-v1",
  "description": "An adaptive chess tutor system using Claude Code + Stockfish + MCP server + TUI",
  "documentationRef": "documentation/general_chess_speedrun_prd_documentation.md",
  "userStories": [
    {
      "id": "US-001",
      "title": "Create install script and project structure",
      "description": "As a developer, I need the install script, shared data models, and directory structure so the project can be set up.",
      "acceptanceCriteria": [
        "scripts/install.sh exists and is executable",
        "Installs Stockfish via brew (macOS) or apt (Linux); skips if already installed",
        "Installs uv if not present, uses uv for environment management",
        "Installs Python deps via uv: python-chess, rich, textual, watchdog, mcp[cli]",
        "Creates data directories: data/sessions, data/games, data/lesson_plans",
        "Creates data/.gitkeep files in each data subdirectory",
        "Initializes data/progress.json with default values if not exists",
        "Initializes data/srs_cards.json as empty array if not exists",
        "Creates pyproject.toml with project metadata, dependencies (python-chess, rich, textual, watchdog, mcp[cli]), and dev deps (pytest)",
        "scripts/models.py exists with GameState and MoveEvaluation dataclasses",
        "GameState fields: game_id, fen, board_display, move_list, last_move, last_move_san, eval_score, player_color, target_elo, is_game_over, result, legal_moves, accuracy, session_number, streak, lesson_name",
        "MoveEvaluation fields: move_san, best_move_san, cp_loss, eval_before, eval_after, classification, is_best, best_line, tactical_motif",
        "python -m py_compile scripts/models.py passes",
        "python -c \"from scripts.models import GameState, MoveEvaluation\" passes"
      ],
      "priority": 1,
      "passes": true,
      "notes": "Uses uv (not pip/venv) for environment management. models.py is the shared schema for MCP server and TUI."
    },
    {
      "id": "US-002",
      "title": "Implement Stockfish engine wrapper",
      "description": "As a developer, I need a Python wrapper around Stockfish for game play and analysis with adaptive difficulty.",
      "acceptanceCriteria": [
        "scripts/engine.py exists with ChessEngine class",
        "Auto-detects Stockfish binary path (checks /usr/local/bin/stockfish, /usr/bin/stockfish, /opt/homebrew/bin/stockfish, which stockfish)",
        "Raises FileNotFoundError with 'Run scripts/install.sh' message if Stockfish not found",
        "new_game() starts a game with configurable target Elo and player_color",
        "set_difficulty() configures engine strength",
        "Sub-1320 Elo uses linear blend: random_pct = max(0, 0.85 - (elo/1320)*0.85), depth = max(1, min(5, elo//250))",
        "get_engine_move() returns moves at configured difficulty",
        "analyze_position() runs full-strength analysis with multipv support",
        "evaluate_move() compares player move to best move, returns MoveEvaluation from scripts.models",
        "Move classification: 0cp=best, 1-30=great, 31-80=good, 81-150=inaccuracy, 151-300=mistake, 300+=blunder",
        "tactical_motif field set to None (future enhancement)",
        "CLI: python scripts/engine.py analyze <fen> prints top 3 lines",
        "CLI: python scripts/engine.py play <elo> plays one engine move and exits",
        "CLI: python scripts/engine.py play <elo> --interactive runs full game loop",
        "python -m py_compile scripts/engine.py passes",
        "python -c \"from scripts.engine import ChessEngine\" passes",
        "tests/test_engine.py exists with pytest tests",
        "python -m pytest tests/test_engine.py passes"
      ],
      "priority": 2,
      "passes": true,
      "notes": "Core dependency - MCP server depends on this. Tests should mock Stockfish for unit tests. Catches EngineTerminatedError and attempts one restart."
    },
    {
      "id": "US-003",
      "title": "Implement SRS spaced repetition manager",
      "description": "As a developer, I need an SRS card manager using the SM-2 algorithm for tracking chess mistakes.",
      "acceptanceCriteria": [
        "scripts/srs.py exists with SRSManager class and SM-2 algorithm",
        "CLI commands: due, review <card_id> <quality>, add (with --fen --player-move --best-move --cp-loss --classification flags), stats",
        "Cards stored in data/srs_cards.json",
        "Card schema: id(uuid), fen, player_move, best_move, cp_loss, classification, motif, explanation, created_at, next_review, interval_hours, ease_factor, repetitions, quality_history",
        "Timestamps stored as ISO 8601 strings",
        "SM-2 intervals in hours: 4, 24, 72, 168, 336, 720; after 720h multiply by ease_factor",
        "Failed cards (quality < 3) reset to interval_hours=4, repetitions=0",
        "Ease factor formula: EF' = EF + (0.1 - (5-q)*(0.08 + (5-q)*0.02)), minimum 1.3",
        "get_due_cards() returns cards where next_review <= now",
        "sm2_update() correctly updates interval, ease_factor, repetitions",
        "All CLI commands output JSON to stdout",
        "Corrupted JSON: backup file and start fresh with []",
        "python -m py_compile scripts/srs.py passes",
        "python -c \"from scripts.srs import SRSManager\" passes",
        "tests/test_srs.py exists with pytest tests for interval progression, failed reset, ease factor bounds, due filtering",
        "python -m pytest tests/test_srs.py passes"
      ],
      "priority": 3,
      "passes": true,
      "notes": "Quality scale 0-5. ValueError for quality out of range or card not found."
    },
    {
      "id": "US-004",
      "title": "MCP server - core game tools",
      "description": "As a developer, I need an MCP server with core game loop tools (new_game, get_board, make_move, engine_move).",
      "acceptanceCriteria": [
        "mcp-server/server.py exists using FastMCP from mcp.server.fastmcp",
        "mcp-server/requirements.txt lists: mcp[cli], python-chess",
        "Server name: chess-speedrun",
        "Games stored in memory dict keyed by game_id (UUID)",
        "Tool: new_game(target_elo, player_color, starting_fen) - starts game, returns GameState dict",
        "Tool: get_board(game_id) - returns current GameState dict with legal moves",
        "Tool: make_move(game_id, move) - player move in SAN notation, returns updated GameState",
        "Tool: engine_move(game_id) - engine makes move at configured difficulty, returns updated GameState",
        "After every make_move and engine_move, writes data/current_game.json using GameState from scripts.models",
        "Atomic file write: write to temp file then os.replace()",
        "Creates data/ directory if it doesn't exist on first write",
        "Invalid game_id returns error dict: {\"error\": \"Game not found: <id>\"}",
        "Illegal move returns error dict with legal moves list",
        "Move when game over returns error dict with result",
        "python -m py_compile mcp-server/server.py passes",
        "python -c \"import mcp.server.fastmcp\" passes"
      ],
      "priority": 4,
      "passes": true,
      "notes": "Imports ChessEngine from scripts.engine and GameState from scripts.models. sys.path manipulation may be needed for imports."
    },
    {
      "id": "US-005",
      "title": "MCP server - analysis tools",
      "description": "As a developer, I need analysis and evaluation tools added to the MCP server (analyze_position, evaluate_move, set_difficulty).",
      "acceptanceCriteria": [
        "Tool: analyze_position(fen, depth=20, multipv=3) added to mcp-server/server.py",
        "analyze_position works on any FEN (no active game required), creates temp ChessEngine",
        "Returns: {fen, depth, lines: [{rank, score_cp, moves, mate_in}]}",
        "Tool: evaluate_move(game_id, move) added - evaluates WITHOUT making the move",
        "Returns MoveEvaluation as dict (move_san, best_move_san, cp_loss, classification, etc.)",
        "Tool: set_difficulty(game_id, target_elo) added - changes difficulty mid-game",
        "set_difficulty clamps Elo to 100-3500 range",
        "Invalid FEN in analyze_position returns error dict",
        "evaluate_move on finished game returns error dict",
        "python -m py_compile mcp-server/server.py passes"
      ],
      "priority": 5,
      "passes": true,
      "notes": "Appends tools to existing mcp-server/server.py from US-004. Does not create new files."
    },
    {
      "id": "US-006",
      "title": "MCP server - utility tools",
      "description": "As a developer, I need utility tools added to the MCP server (PGN, legal moves, undo, set_position, SRS integration).",
      "acceptanceCriteria": [
        "Tool: get_game_pgn(game_id) added - returns valid PGN string",
        "Tool: get_legal_moves(game_id, square=None) added - lists legal moves, optionally filtered by source square",
        "Tool: undo_move(game_id) added - undoes last move; if last two were player+engine, undoes both",
        "undo_move updates data/current_game.json after undo",
        "undo_move on empty game (no moves) returns error dict",
        "Tool: set_position(fen) added - creates new game from custom FEN for puzzles, defaults to full-strength engine",
        "Tool: srs_add_card(game_id, move, explanation) added - saves current position as SRS mistake card via scripts.srs",
        "get_legal_moves on empty square returns empty list",
        "set_position with invalid FEN returns error dict",
        "PGN of game with no moves returns valid minimal PGN",
        "python -m py_compile mcp-server/server.py passes"
      ],
      "priority": 6,
      "passes": true,
      "notes": "Appends tools to existing mcp-server/server.py. srs_add_card is a bonus tool for tutor to save mistakes during games."
    },
    {
      "id": "US-007",
      "title": "Implement Terminal UI with Rich",
      "description": "As a user, I need a terminal chess board display that auto-updates during games by watching current_game.json.",
      "acceptanceCriteria": [
        "scripts/tui.py exists using Rich library",
        "Renders chess board with Unicode piece symbols (K=\u2654, Q=\u2655, R=\u2656, B=\u2657, N=\u2658, P=\u2659, etc.)",
        "Board has alternating dark/light square colors",
        "Highlights last move source/destination squares",
        "Board flips orientation if player is black",
        "Sidebar shows: move list (numbered SAN), eval bar with centipawn score, accuracy percentages",
        "Header shows: session number, streak, lesson name",
        "Layout: board on left (ratio 2), sidebar on right (ratio 1)",
        "Watches data/current_game.json using watchdog at ~4Hz (250ms interval)",
        "Graceful handling of partial/corrupt JSON writes (skip and wait for next poll)",
        "Missing current_game.json shows 'Waiting for game...' message",
        "data/sample_game.json created with a valid mid-game GameState",
        "python scripts/tui.py --sample renders sample board and exits (no watch loop)",
        "Reads GameState fields from JSON with fallback defaults for missing fields",
        "python -m py_compile scripts/tui.py passes",
        "python -c \"from scripts.tui import render_board\" passes"
      ],
      "priority": 7,
      "passes": true,
      "notes": "Standalone testing via --sample flag. No MCP dependency for testing. Imports GameState from scripts.models for type reference."
    },
    {
      "id": "US-008",
      "title": "Create curriculum and pedagogy reference files",
      "description": "As a chess tutor, I need reference materials for curriculum structure and teaching methodology.",
      "acceptanceCriteria": [
        "references/curriculum.md exists with full curriculum: Foundation (0-600), Tactical Basics (600-1000), Intermediate (1000-1500)",
        "Each phase has: lessons list, prerequisites, learning objectives",
        "references/chess-pedagogy.md exists with GM coaching methodology",
        "references/learning-science.md exists with deliberate practice and Zone of Proximal Development theory",
        "references/elo-milestones.md exists with specific skills per Elo range (at least 0-600, 600-1000, 1000-1500)",
        "Each file is well-structured with at least 3 major sections with headers",
        "Files cross-reference each other where relevant"
      ],
      "priority": 8,
      "passes": true,
      "notes": "Static content files. No code validation needed, just file existence and section structure."
    },
    {
      "id": "US-009",
      "title": "Create tactical patterns and mistakes reference files",
      "description": "As a chess tutor, I need reference materials for tactical patterns and common beginner mistakes.",
      "acceptanceCriteria": [
        "references/tactical-patterns.md exists covering: forks (knight/queen/pawn), pins (absolute/relative), skewers, discovered attacks, discovered check, double check, back-rank threats",
        "Each tactical pattern has: name, description, recognition cues, teaching approach",
        "references/common-mistakes.md exists covering: hanging pieces, ignoring threats, premature queen development, not castling, moving same piece twice, not controlling center",
        "Each mistake has: description, why beginners do it, teaching response",
        "references/opening-guide.md exists with at least 3 beginner-friendly openings with explanations",
        "Each file has well-structured sections with headers"
      ],
      "priority": 9,
      "passes": true,
      "notes": "Static content files. Must be created before SKILL.md (US-011) so it can reference them."
    },
    {
      "id": "US-010",
      "title": "Create curated puzzle sets with validation",
      "description": "As a chess tutor, I need puzzle positions organized by tactical motif with programmatic FEN validation.",
      "acceptanceCriteria": [
        "puzzles/forks.json exists with 10+ fork puzzle positions",
        "puzzles/pins.json exists with 10+ pin puzzle positions",
        "puzzles/skewers.json exists with 10+ skewer puzzle positions",
        "puzzles/back-rank.json exists with 10+ back-rank mate puzzles",
        "puzzles/checkmate-patterns.json exists with 10+ checkmate puzzles",
        "puzzles/beginner-endgames.json exists with 10+ endgame positions",
        "Each puzzle has: fen, solution_moves (UCI), solution_san, motif, difficulty, explanation",
        "scripts/validate_puzzles.py exists and validates all puzzle files",
        "Validation checks: FEN loads in python-chess without error, solution_moves are legal from position, sequential solution moves are each legal after previous",
        "python scripts/validate_puzzles.py exits with code 0",
        "python -m py_compile scripts/validate_puzzles.py passes"
      ],
      "priority": 10,
      "passes": true,
      "notes": "LLM-generated FENs are often invalid - programmatic validation is critical. Must be created before SKILL.md (US-011)."
    },
    {
      "id": "US-011",
      "title": "Create SKILL.md chess tutor skill file",
      "description": "As a Claude Code user, I need the SKILL.md file that transforms Claude Code into an adaptive chess tutor.",
      "acceptanceCriteria": [
        "SKILL.md exists with proper frontmatter (name, description, triggers: chess, play chess, chess lesson)",
        "Defines 3 expert roles: GM Teacher, Learning Psychologist, Behavioral Specialist",
        "Documents Quick Start flow: read progress, check MCP, load references, proceed",
        "Documents core loop: Play -> Analyze -> Teach -> Replay -> Plan",
        "Move evaluation thresholds: <=30 acknowledge, 31-80 mention, 81-200 teach, >200 intervene",
        "Language adaptation by Elo range (<600 simple, 600-1000 moderate, 1000-1500 technical)",
        "Post-game flow: save PGN, show summary, identify teaching positions, offer replay",
        "Session ending flow: save log, update progress, generate 3-perspective plan",
        "Difficulty control table: accuracy vs Elo offset mapping",
        "SRS system documentation with SM-2 intervals",
        "Curriculum phases summary referencing references/curriculum.md",
        "3-Perspective lesson plan framework (GM, Psychologist, Behaviorist)",
        "File references section pointing to actual files in references/, puzzles/, data/ directories"
      ],
      "priority": 11,
      "passes": true,
      "notes": "All referenced files (references/*, puzzles/*) now exist from US-008, US-009, US-010. Use relative paths."
    },
    {
      "id": "US-012",
      "title": "Create export script",
      "description": "As a developer, I need an export script for progress reports and game summaries in markdown format.",
      "acceptanceCriteria": [
        "scripts/export.py exists with export_progress() and export_games() functions",
        "CLI: python scripts/export.py progress - exports progress report from data/progress.json",
        "CLI: python scripts/export.py games - exports game summaries from data/sessions/ and data/games/",
        "Output format: markdown to stdout",
        "Progress report includes: current level, sessions completed, streak, accuracy trends, areas for improvement, SRS status",
        "Games report includes: per-game date, opponent Elo, result, accuracy, key mistakes",
        "No progress file: prints 'No progress data found. Play some games first!'",
        "No game files: prints 'No games found.'",
        "Corrupted JSON files: skip with warning",
        "python -m py_compile scripts/export.py passes",
        "python -c \"from scripts.export import export_progress, export_games\" passes"
      ],
      "priority": 12,
      "passes": true,
      "notes": "Markdown format chosen for human readability and Claude Code consumption."
    },
    {
      "id": "US-013",
      "title": "Create Claude settings and run integration verification",
      "description": "As a developer, I need .claude/settings.json for MCP server config and final integration verification.",
      "acceptanceCriteria": [
        ".claude/settings.json exists with mcpServers config",
        "MCP config: command=python, args=[mcp-server/server.py]",
        "Creates .claude/ directory if it doesn't exist",
        "Merges with existing settings.json if present (don't overwrite)",
        "python -m py_compile passes on ALL .py files in scripts/ and mcp-server/",
        "python scripts/validate_puzzles.py exits with code 0",
        "All required directories exist: data/sessions, data/games, data/lesson_plans, references/, puzzles/, mcp-server/, scripts/, .claude/",
        "All required files exist: scripts/install.sh, scripts/engine.py, scripts/srs.py, scripts/tui.py, scripts/export.py, scripts/models.py, scripts/validate_puzzles.py, mcp-server/server.py, SKILL.md"
      ],
      "priority": 13,
      "passes": true,
      "notes": "Final story - verification that all pieces are in place. Should be the last story implemented."
    },
    {
      "id": "US-014",
      "title": "Auto-save PGN on game over",
      "description": "As a user, I need completed games to be automatically saved as PGN files so no game data is lost when the post-game flow is interrupted.",
      "acceptanceCriteria": [
        "Add `from datetime import datetime, timezone` import to mcp-server/server.py",
        "New helper function `_auto_save_pgn(game_id, game)` in mcp-server/server.py near `_sync_game_json`",
        "Builds PGN from board.move_stack using chess.pgn.Game",
        "PGN headers include: Event='Chess Speedrun', Site='Chess Rocket', Date (UTC), Result",
        "PGN White/Black headers include Elo labels: 'Player (Elo N)' vs 'Stockfish (Elo N)'",
        "Player Elo read from data/progress.json (fallback to 'unknown' if file missing or unreadable)",
        "Writes atomically to data/games/game_{timestamp}_{game_id[:8]}.pgn (temp file + os.replace)",
        "Creates data/games/ directory if it doesn't exist",
        "Called automatically in make_move() after board.push() when board.is_game_over() is True",
        "Called automatically in engine_move() after board.push() when board.is_game_over() is True",
        "Does NOT affect the return value of make_move or engine_move (fire-and-forget save)",
        "python -m py_compile mcp-server/server.py passes",
        "python -c \"import mcp.server.fastmcp\" passes"
      ],
      "priority": 14,
      "passes": true,
      "notes": "See plan.md section 'US-014' for implementation details. Modifies existing make_move and engine_move functions in mcp-server/server.py."
    },
    {
      "id": "US-015",
      "title": "Add save_session MCP tool",
      "description": "As a tutor, I need a single MCP tool call that persists all session data (progress, session log) so nothing is lost between games.",
      "acceptanceCriteria": [
        "New @mcp.tool() save_session(game_id, estimated_elo=None, accuracy_pct=None, lesson_name='', areas_for_improvement=None, summary='') in mcp-server/server.py",
        "Loads data/progress.json with fallback to defaults if missing: {current_elo: 400, estimated_elo: 400, sessions_completed: 0, streak: 0, total_games: 0, accuracy_history: [], areas_for_improvement: [], last_session: null}",
        "Updates progress: current_elo and estimated_elo set to estimated_elo param (or keep existing if None)",
        "Increments sessions_completed by 1",
        "Increments total_games by 1",
        "Increments streak by 1 (always, regardless of game result)",
        "Appends accuracy_pct to accuracy_history (if not None)",
        "Sets last_session to current ISO 8601 UTC timestamp",
        "Sets areas_for_improvement if provided (replaces existing list)",
        "Writes data/progress.json atomically (temp file + os.replace)",
        "Writes session log to data/sessions/session_NNN.json (NNN = zero-padded sessions_completed)",
        "Session log contains: session_id, game_id, date (ISO 8601), result, player_color, target_elo, estimated_elo, total_moves, accuracy_pct, lesson_name, areas_for_improvement, summary",
        "Creates data/sessions/ directory if it doesn't exist",
        "Returns dict with 'message', 'session_id', 'session_file', 'progress' keys",
        "Invalid game_id returns error dict: {\"error\": \"Game not found: <id>\"}",
        "python -m py_compile mcp-server/server.py passes"
      ],
      "priority": 15,
      "passes": true,
      "notes": "See plan.md section 'US-015' for implementation details. Appends new tool to existing mcp-server/server.py."
    },
    {
      "id": "US-016",
      "title": "Add create_srs_cards_from_game MCP tool",
      "description": "As a tutor, I need a tool that batch-analyzes a completed game and creates SRS cards for all significant mistakes in one call.",
      "acceptanceCriteria": [
        "New @mcp.tool() create_srs_cards_from_game(game_id, cp_threshold=80) in mcp-server/server.py",
        "Returns error dict if game is not over (board.is_game_over() is False)",
        "Returns error dict if game_id not found",
        "Creates fresh ChessEngine at full strength (set_difficulty(3000)) for analysis",
        "Replays game from game['starting_fen'], evaluates each player move at depth 20",
        "Determines player moves based on game['player_color'] and board turn",
        "For moves with cp_loss >= cp_threshold: creates SRS card via SRSManager.add_card()",
        "SRS card explanation includes move number, player move, best move, and cp_loss",
        "Closes analysis engine after completion (analysis_engine.close())",
        "Returns dict with: game_id, total_player_moves, mistakes_found, cards_created, mistakes list (each with fen, move_number, player_move, best_move, cp_loss, classification), card_ids",
        "Game with no moves returns: {game_id, total_player_moves: 0, mistakes_found: 0, cards_created: 0, mistakes: [], card_ids: []}",
        "python -m py_compile mcp-server/server.py passes"
      ],
      "priority": 16,
      "passes": true,
      "notes": "See plan.md section 'US-016' for implementation details. Uses fixed depth 20 analysis (15-30s for full game is acceptable). Appends new tool to existing mcp-server/server.py."
    },
    {
      "id": "US-017",
      "title": "Fix export.py estimated_elo key mismatch",
      "description": "As a developer, I need export.py to correctly read the player's Elo from progress.json regardless of which key name is used.",
      "acceptanceCriteria": [
        "scripts/export.py line 39 updated: progress.get('estimated_elo', progress.get('current_elo', 'Unknown'))",
        "export_progress() works with progress.json containing only 'current_elo' key",
        "export_progress() works with progress.json containing only 'estimated_elo' key",
        "export_progress() works with progress.json containing both keys (estimated_elo takes priority)",
        "python -m py_compile scripts/export.py passes",
        "python -c \"from scripts.export import export_progress, export_games\" passes"
      ],
      "priority": 17,
      "passes": true,
      "notes": "See plan.md section 'US-017'. One-line fix. The save_session tool (US-015) writes both keys for forward compatibility."
    },
    {
      "id": "US-018",
      "title": "Update CLAUDE.md and SKILL.md for post-game automation",
      "description": "As a tutor, I need CLAUDE.md and SKILL.md to reference the new automated tools instead of manual file write instructions.",
      "acceptanceCriteria": [
        "CLAUDE.md Post-Game Flow section updated: notes PGN is auto-saved on game over",
        "CLAUDE.md Post-Game Flow section updated: references create_srs_cards_from_game(game_id) for batch SRS",
        "CLAUDE.md Session End Flow section updated: references save_session(game_id, ...) instead of manual file writes",
        "CLAUDE.md MCP Tools Reference table updated to include save_session and create_srs_cards_from_game",
        "SKILL.md section 7 (Post-Game Flow) updated to reference auto-saved PGN and create_srs_cards_from_game",
        "SKILL.md section 8 (Session Ending Flow) updated to reference save_session tool",
        "SKILL.md section 13 (File References) system files table updated to mention new tools",
        "Both files are valid markdown with no broken formatting"
      ],
      "priority": 18,
      "passes": true,
      "notes": "See plan.md section 'US-018'. Documentation-only changes. No code validation needed."
    },
    {
      "id": "US-019",
      "title": "End-to-end post-game flow integration test",
      "description": "As a developer, I need a pytest integration test that exercises the full post-game chain (auto PGN, save_session, batch SRS, export) using real Stockfish.",
      "acceptanceCriteria": [
        "tests/test_post_game.py exists",
        "Test imports server functions directly from mcp-server/server.py (not via MCP protocol)",
        "Test calls new_game() to start a game",
        "Test plays a short game to completion (e.g., use set_position with a near-mate FEN, then make the mating move)",
        "Test verifies PGN was auto-saved: at least one .pgn file exists in data/games/ after game over",
        "Test calls save_session() and verifies data/progress.json was updated (sessions_completed > 0, streak > 0)",
        "Test verifies a session log file was created in data/sessions/",
        "Test calls create_srs_cards_from_game() and verifies it returns without error (cards_created >= 0)",
        "Test calls export_progress() from scripts.export and verifies it returns non-empty markdown string",
        "Test cleans up test data files after run (restore original progress.json and srs_cards.json, remove test PGN and session files)",
        "Uses real Stockfish (requires Stockfish installed)",
        "python -m py_compile tests/test_post_game.py passes",
        "uv run python -m pytest tests/test_post_game.py -v passes",
        "uv run python -m pytest tests/ passes (all existing tests still pass)"
      ],
      "priority": 19,
      "passes": true,
      "notes": "See plan.md section 'US-019'. Final verification story. Uses real Stockfish for true integration testing. Test should use pytest fixtures for setup/teardown of data files."
    },
    {
      "id": "US-020",
      "title": "Build openings data pipeline",
      "description": "As a developer, I need a build script that downloads 3,627 chess openings from Lichess and creates a SQLite database + JSON trie for fast lookup.",
      "acceptanceCriteria": [
        "scripts/build_openings_db.py exists and is runnable via uv run python scripts/build_openings_db.py",
        "Downloads 5 TSV files from https://github.com/lichess-org/chess-openings/raw/master/{a,b,c,d,e}.tsv",
        "Caches downloaded TSVs in data/openings_raw/ to avoid re-downloading on subsequent runs",
        "Creates data/openings.db (SQLite) with table 'openings' containing columns: id, eco_volume, eco, name, family, pgn, uci, epd, num_moves",
        "eco_volume derived from first character of eco code (A-E)",
        "family derived from opening name before ':' (or full name if no ':')",
        "num_moves is count of space-split UCI moves",
        "SQLite indexes on: eco, eco_volume, family, name",
        "Creates data/openings_trie.json - nested dict keyed on UCI moves with '_eco' and '_name' at named nodes",
        "data/openings.db contains exactly 3,627 rows (or close, matching Lichess source)",
        "data/openings_trie.json is valid JSON and under 1MB",
        "Delete the chess-openings/ directory (LFS Parquet replaced by TSV download)",
        "Add data/openings_raw/, data/openings.db, data/openings_trie.json to .gitignore",
        "Add 'uv run python scripts/build_openings_db.py' step to scripts/install.sh",
        "Zero new dependencies - uses only stdlib (urllib.request, csv, sqlite3, json)",
        "Clear error message if download fails (no internet): prints URL that failed and exits with code 1",
        "python -m py_compile scripts/build_openings_db.py passes",
        "uv run python scripts/build_openings_db.py completes without error"
      ],
      "priority": 20,
      "passes": false,
      "notes": "See ~/.claude/plans/crispy-weaving-candy.md Phase 1. Source: Lichess GitHub TSVs (~200KB total). The chess-openings/ directory with LFS Parquet pointer should be deleted."
    },
    {
      "id": "US-021",
      "title": "Opening recognition library",
      "description": "As a developer, I need an OpeningsDB class that provides fast opening identification via trie lookup and rich querying via SQLite.",
      "acceptanceCriteria": [
        "scripts/openings.py exists with OpeningsDB class",
        "Constructor takes db_path and trie_path parameters with defaults pointing to data/openings.db and data/openings_trie.json",
        "Trie loaded into memory once at construction time",
        "identify_opening(uci_moves: list[str]) returns dict with eco, eco_volume, name, family, pgn, moves_matched keys, or None if no match",
        "identify_opening returns the DEEPEST matching named node (most specific opening)",
        "identify_opening returns None when current moves don't match any trie path (out of book)",
        "get_continuations(uci_moves: list[str]) returns list of dicts for named openings branching from current position",
        "search_openings(query, eco=None, eco_volume=None, limit=20) does LIKE search on name and eco columns",
        "get_opening_by_eco(eco) returns all openings matching an ECO code",
        "get_opening_lines(family) returns all variations of an opening family",
        "get_openings_for_level(elo) returns level-appropriate openings: Phase 1 (0-600) <= 4 half-moves common families, Phase 2 (600-1000) 4-10 half-moves, Phase 3 (1000+) full access",
        "get_random_opening(eco_volume=None, max_moves=None) returns a random opening with optional filters",
        "Graceful degradation: if trie/db files don't exist, methods return None or empty lists (no crash, no exception)",
        "All methods return plain dicts (not dataclasses), matching MCP server pattern",
        "SQLite connections opened per-query for thread safety",
        "python -m py_compile scripts/openings.py passes",
        "python -c \"from scripts.openings import OpeningsDB\" passes"
      ],
      "priority": 21,
      "passes": false,
      "notes": "See ~/.claude/plans/crispy-weaving-candy.md Phase 2. Depends on US-020 (needs data/openings.db and data/openings_trie.json). Memory ~4MB for trie."
    },
    {
      "id": "US-022",
      "title": "Opening MCP tools",
      "description": "As a tutor, I need MCP tools to identify, search, explore, suggest, and quiz openings so I can teach from the full 3,627-opening database.",
      "acceptanceCriteria": [
        "mcp-server/openings_tools.py exists with register_openings_tools(mcp, games, data_dir, project_root) function",
        "register_openings_tools registers 5 new @mcp.tool() decorated functions on the mcp instance",
        "Tool: identify_opening(game_id) - extracts UCI moves from game's board.move_stack, returns {eco, name, family, moves_matched, pgn} or None if out of book",
        "Tool: search_openings(query, eco=None, eco_volume=None, limit=20) - searches by name/ECO, returns {results: [...], total: int}",
        "Tool: get_opening_details(eco) - returns {eco, family, variations: [...]} for all openings with that ECO code",
        "Tool: suggest_opening(elo=None, color='white') - returns {suggestions: [{name, eco, pgn, epd}...]} appropriate for level. No 'why' field - Claude explains using references. Reads elo from data/progress.json if param is None",
        "Tool: opening_quiz(eco=None, difficulty='beginner') - picks opening, plays N-1 moves, calls set_position() to create real game, returns {game_id, opening_name, opening_eco, position_fen, moves_so_far, correct_move_san}",
        "opening_quiz tracks quizzed openings in data/progress.json under 'openings_studied' list to avoid repetition",
        "opening_quiz resets openings_studied when all openings at that level have been covered",
        "All 5 tools return error dicts {\"error\": \"Openings database not built. Run: uv run python scripts/build_openings_db.py\"} if openings.db or trie.json don't exist",
        "Invalid game_id in identify_opening returns error dict",
        "mcp-server/server.py modified to import and call register_openings_tools() before mcp.run()",
        "python -m py_compile mcp-server/openings_tools.py passes",
        "python -m py_compile mcp-server/server.py passes"
      ],
      "priority": 22,
      "passes": false,
      "notes": "See ~/.claude/plans/crispy-weaving-candy.md Phase 3. Depends on US-021. server.py is 864 lines - new tools MUST go in openings_tools.py, not server.py. Only ~15 lines added to server.py for import and registration."
    },
    {
      "id": "US-023",
      "title": "Live game opening integration",
      "description": "As a user, I need the tutor and TUI to show what opening I'm playing during a game, clearing when I leave book.",
      "acceptanceCriteria": [
        "mcp-server/server.py _build_game_state() calls openings_db.identify_opening() with UCI moves from game's board.move_stack",
        "GameState dict includes 'current_opening' field: dict with {eco, name, family, moves_matched} or None",
        "current_opening is set to None when game moves no longer match any trie path (out of book)",
        "current_opening updates after every make_move and engine_move call",
        "scripts/models.py GameState dataclass has new field: current_opening: dict | None = None",
        "scripts/tui.py displays opening name + ECO code in sidebar when current_opening is not None",
        "TUI display format: 'Opening: {name} ({eco})' or similar",
        "When current_opening is None (out of book), TUI shows nothing or 'Out of book' for opening",
        "data/current_game.json includes current_opening field after moves",
        "Opening identification adds no perceptible latency (trie lookup is O(d) where d = moves played)",
        "If openings DB not built, current_opening is simply None (graceful degradation, no crash)",
        "python -m py_compile mcp-server/server.py passes",
        "python -m py_compile scripts/models.py passes",
        "python -m py_compile scripts/tui.py passes",
        "uv run python scripts/tui.py --sample still works"
      ],
      "priority": 23,
      "passes": false,
      "notes": "See ~/.claude/plans/crispy-weaving-candy.md Phase 4. Depends on US-021 and US-022. Key behavior: CLEAR current_opening to None when out of book (don't keep showing last known opening)."
    },
    {
      "id": "US-024",
      "title": "Opening puzzle generation",
      "description": "As a tutor, I need opening-based puzzles in two styles: 'next book move' knowledge tests and 'opening trap' refutation puzzles.",
      "acceptanceCriteria": [
        "scripts/generate_opening_puzzles.py exists",
        "CLI: uv run python scripts/generate_opening_puzzles.py creates both puzzle files",
        "puzzles/opening-moves.json created with ~30 'next book move' puzzles",
        "opening-moves puzzles: FEN is position after N-1 moves, solution is move N from the opening PGN",
        "opening-moves motif field is 'opening'",
        "opening-moves difficulty: 1-4 half-moves = beginner, 5-8 = intermediate, 9+ = advanced",
        "opening-moves covers all 5 ECO volumes (A through E)",
        "puzzles/opening-traps.json created with ~20 opening trap puzzles",
        "opening-traps includes ~10 curated famous traps (Scholar's Mate, Fishing Pole, Lasker Trap, Legal's Mate, Englund Gambit Trap, etc.) with hardcoded FENs and refutations",
        "opening-traps includes ~10 auto-generated traps: positions where a natural bad move leads to >150cp punishment, verified by Stockfish",
        "opening-traps motif field is 'opening_trap'",
        "Both files use existing puzzle schema: {fen, solution_moves (UCI), solution_san, motif, difficulty, explanation}",
        "All generated FENs are valid (loadable by python-chess)",
        "All solution_moves are legal from the given FEN position",
        "scripts/validate_puzzles.py updated to include 'opening-moves.json' and 'opening-traps.json' in expected files list",
        "uv run python scripts/validate_puzzles.py exits with code 0 (all puzzle files valid)",
        "python -m py_compile scripts/generate_opening_puzzles.py passes"
      ],
      "priority": 24,
      "passes": false,
      "notes": "See ~/.claude/plans/crispy-weaving-candy.md Phase 5. Depends on US-020 (reads from data/openings.db). Trap generation uses Stockfish - run once, commit the JSON output. Curated traps are hardcoded in the script."
    },
    {
      "id": "US-025",
      "title": "Opening integration documentation updates",
      "description": "As a tutor and developer, I need CLAUDE.md, SKILL.md, and reference files updated to document the new opening tools, puzzles, and teaching workflow.",
      "acceptanceCriteria": [
        "CLAUDE.md MCP Tools Reference table includes all 5 new tools: identify_opening, search_openings, get_opening_details, suggest_opening, opening_quiz",
        "CLAUDE.md Data Files table includes data/openings.db and data/openings_trie.json",
        "CLAUDE.md Core Loop Play phase mentions opening identification after each move",
        "CLAUDE.md has new 'Opening Study Mode' section describing how to use search/suggest/quiz tools",
        "CLAUDE.md puzzle table updated to include puzzles/opening-moves.json and puzzles/opening-traps.json",
        "SKILL.md mirrors all CLAUDE.md changes (new tools, opening study mode, puzzles)",
        "references/opening-guide.md updated with note about full 3,627-opening database accessible via search_openings and get_opening_details tools",
        "references/curriculum.md updated with opening study goals per phase: Phase 1 learn 2-3 basic openings, Phase 2 expand to 5-6 with ECO families, Phase 3 full repertoire with opening traps",
        "scripts/install.sh includes 'uv run python scripts/build_openings_db.py' step",
        "All modified files are valid markdown with no broken formatting",
        "All modified .sh files are executable"
      ],
      "priority": 25,
      "passes": false,
      "notes": "See ~/.claude/plans/crispy-weaving-candy.md Phase 6. Depends on US-022, US-023, US-024 (documents tools and features from those stories). Documentation-only plus install.sh update."
    },
    {
      "id": "US-026",
      "title": "Opening integration tests",
      "description": "As a developer, I need comprehensive tests for the openings library, MCP tools, and live game integration.",
      "acceptanceCriteria": [
        "tests/test_openings.py exists with pytest tests",
        "Trie tests: identify_opening(['e2e4', 'c7c5']) returns Sicilian Defense (B20)",
        "Trie tests: identify_opening([]) returns None",
        "Trie tests: identify_opening with non-book moves returns None (out of book)",
        "Trie tests: identify_opening returns deepest match (most specific variation)",
        "SQLite tests: search_openings('Italian') returns Italian Game variations",
        "SQLite tests: search by ECO code returns correct results",
        "SQLite tests: get_openings_for_level(400) returns only short/common openings",
        "SQLite tests: get_openings_for_level(1200) returns wider selection",
        "Graceful degradation test: OpeningsDB with nonexistent paths returns None/empty (no crash)",
        "MCP tool tests: identify_opening with valid game_id returns opening info",
        "MCP tool tests: search_openings returns results with total count",
        "MCP tool tests: suggest_opening returns level-appropriate list",
        "MCP tool tests: opening_quiz creates a game and returns correct_move_san",
        "MCP tool tests: all tools return error dict when openings DB not built",
        "Quiz tracking test: opening_quiz updates openings_studied in progress.json",
        "python -m py_compile tests/test_openings.py passes",
        "uv run python -m pytest tests/test_openings.py -v passes",
        "uv run python -m pytest tests/ -v passes (no regressions on existing tests)"
      ],
      "priority": 26,
      "passes": false,
      "notes": "See ~/.claude/plans/crispy-weaving-candy.md Phase 7. Depends on US-021, US-022, US-023. Tests require data/openings.db and data/openings_trie.json to exist (run build_openings_db.py first). Use pytest fixtures for test data setup/teardown."
    }
  ]
}